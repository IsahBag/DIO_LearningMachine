{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # convertendo a imagem para tensor\n",
    "\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # carregando a parte de treino do dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # criando um buffer para pegar os dados por parte\n",
    "\n",
    "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # carregando a parte de treino do dataset\n",
    "valloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # criando um buffer para pegar os dados por parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x271edd28110>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)  # iterador criado a partir de 'trainloader'\n",
    "imagens, etiquetas = next(dataiter)  # obtém o próximo lote de imagens e etiquetas do iterador 'dataiter'\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape)  # verifica as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape)  # verifica as dimensões do tensor de cada etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo,self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada: 784 neurônios que se ligam a 128  \n",
    "        self.linear2 = nn.Linear(128, 64) # camada interna 1: 128 neurônios que se ligam a 64\n",
    "        self.linear3 = nn.Linear(64, 10) # camada interna 2: 64 neurônios que se ligam a 10\n",
    "        # não é necessário definir a camada de saída, pois só é preciso pegar o output da camada interna 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X))  # função de ativação da camada de entrada para a camada interna 1\n",
    "        X = F.relu(self.linear2(X))  # função de ativação da camada interna 1 para a camada interna 2    \n",
    "        X = self.linear3(X)  # função de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1)  # dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)  # definindo a política de atualização dos pesos e da bias\n",
    "    inicio = time()  # timer para calcular o tempo do treino\n",
    "\n",
    "    criterio = nn.NLLLoss()  # definindo o criterio para calcular a perda\n",
    "    EPOCHS = 10  # número de epochs que o algoritmo rodará\n",
    "    modelo.train()  # ativação do modo de treinamento do modelo\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0  # inicialização da perda acumulada da epoch em questão\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "\n",
    "            imagens = imagens.view(imagens.shape[0], -1)  # convertendo as imagens para vetores de 28*28 casas\n",
    "            otimizador.zero_grad()  # zerando os gradientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device))  # colocando os dados no modelo\n",
    "            perda_instantanea =  criterio(output, etiquetas.to(device))  # calculando a perda da epoch em questão\n",
    "\n",
    "            perda_instantanea.backward()  # back propagation a partir da perda\n",
    "\n",
    "            otimizador.step()  # atualizando os pesos e as bias\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item()  # atualizando a perda acumulada\n",
    "            \n",
    "        else: \n",
    "            print(f\"Epoch {epoch+1} - Perda resultante: {perda_acumulada/len(trainloader)}\")\n",
    "    print(f\"\\nTempo de treino (em minutos) = {(time()-inicio)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, valloader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # desativar o autograd para acelerar a validacão\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device))  # output do modelo em escala logaritmica\n",
    "\n",
    "            ps = torch.exp(logps)  # converte o output para escala normal\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab))  # converte o tensor em um número, no caso, o número que o modelo previu como correto\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            if(etiqueta_certa == etiqueta_pred):  # compara a previsão com o valor correto\n",
    "                conta_corretas += 1\n",
    "            conta_todas +=1\n",
    "    \n",
    "    print(f\"Total de imagens testadas: {conta_todas}\")\n",
    "    print(f\"\\nPrecisão do modelo: {conta_corretas*100/conta_todas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()  # inicializa o modelo\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # modelo rodará na GPU se possível\n",
    "modelo.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
